{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Battery life cycle prediction - deep learning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import ElasticNet, LinearRegression, LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import gc\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "import src.constants as cst\n",
    "import src.features.rebuilding_features as rf\n",
    "import src.models.train_model as tm\n",
    "#from src.data.data_class import BatteryData\n",
    "#from src.data.load_data import DataLoader\n",
    "#from src.data.wrangle_data import DataWrangler\n",
    "\n",
    "#from rebuilding_features import load_batches_to_dict\n",
    "from src.visualization.helpers import print_dict_keys\n",
    "from os.path import join\n",
    "import src.models.data_pipeline as dp\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import style\n",
    "import itertools\n",
    "import warnings\n",
    "import json\n",
    "import seaborn as sns\n",
    "import src.constants as cst\n",
    "\n",
    "import src.models.data_pipeline as dp  # TODO: Have to refactor this code out of this class.\n",
    "import src.models.split_model as split_model\n",
    "import src.models.full_cnn_model as full_cnn_model\n",
    "from src.models.callbacks import CustomCheckpoints\n",
    "\n",
    "warnings.filterwarnings('ignore')\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "physical_devices = tf.config.list_physical_devices('GPU')\n",
    "try:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "except:\n",
    "    # Invalid device or cannot modify virtual devices once initialized.\n",
    "    pass"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "config = tf.compat.v1.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "config.log_device_placement = True\n",
    "#session = tf.compat.v1.Session(config=config)\n",
    "#tf.compat.v1.keras.backend.set_session(session)\n",
    "import os\n",
    "from pandas import datetime\n",
    "\n",
    "DATA_DIR = join(\"../../data/external\")\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print (physical_devices)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "def calculate_steps_per_epoch(data_dir, dataset_config):\n",
    "    temp_dataset = dp.create_dataset(data_dir=data_dir,\n",
    "                                     window_size=dataset_config[\"window_size\"],\n",
    "                                     shift=dataset_config[\"shift\"],\n",
    "                                     stride=dataset_config[\"stride\"],\n",
    "                                     batch_size=dataset_config[\"batch_size\"],\n",
    "                                     repeat=False)\n",
    "    steps_per_epoch = 0\n",
    "    for batch in temp_dataset:\n",
    "        steps_per_epoch += 1\n",
    "    return steps_per_epoch\n",
    "\n",
    "def get_tboard_dir():\n",
    "    run_timestr = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "    tboard_dir = os.path.join(cst.TENSORBOARD_DIR, \"jobs\", run_timestr)\n",
    "    return tboard_dir"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Deep Learning model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We build a deep learning model by\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "args = tm.get_args()\n",
    "#model_trainer = tm.ModelTrainer(None, args)\n",
    "#model_trainer.train_and_evaluate()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph\\jobs\\20220930-183730\n"
     ]
    }
   ],
   "source": [
    "scaling_factors = dp.load_scaling_factors()\n",
    "dataset_dir = cst.TEST_SET\n",
    "window_size = 20\n",
    "shift = 5\n",
    "stride = 1\n",
    "batch_size = 32\n",
    "hparams = None\n",
    "save_from = 80\n",
    "tboard = get_tboard_dir()\n",
    "\n",
    "print (tboard)\n",
    "\n",
    "dataset = dp.create_dataset(dataset_dir,\n",
    "                            window_size=window_size,\n",
    "                            shift=shift,  # Can vary during validation\n",
    "                            stride=stride,\n",
    "                            batch_size=batch_size,  # Can vary during validation\n",
    "                            cycle_length=1,  # To match original order (so no files get interleaved)\n",
    "                            num_parallel_calls=1,  # Has to be equal or below cycle_length\n",
    "                            shuffle=None,  # To match original order\n",
    "                            repeat=None)\n",
    "\n",
    "# Config datasets for consistent usage\n",
    "ds_config = dict(window_size=window_size,\n",
    "                 shift=shift,\n",
    "                 stride=stride,\n",
    "                 batch_size=batch_size)\n",
    "ds_train_path = cst.TRAIN_SET\n",
    "ds_val_path = cst.TEST_SET"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Graph\\jobs\\20220930-182507\n",
      "Using split model!\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Qdlin (InputLayer)              [(None, 20, 1000, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tdlin (InputLayer)              [(None, 20, 1000, 1) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "detail_concat (Concatenate)     (None, 20, 1000, 2)  0           Qdlin[0][0]                      \n",
      "                                                                 Tdlin[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "convolution (TimeDistributed)   (None, 20, 334, 32)  608         detail_concat[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv_pool (TimeDistributed)     (None, 20, 167, 32)  0           convolution[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (TimeDistributed)         (None, 20, 56, 64)   18496       conv_pool[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (TimeDistributed)         (None, 20, 28, 64)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv3 (TimeDistributed)         (None, 20, 10, 128)  73856       pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool3 (TimeDistributed)         (None, 20, 5, 128)   0           conv3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "convolution_flat (TimeDistribut (None, 20, 640)      0           pool3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_cnn (TimeDistributed)   (None, 20, 640)      0           convolution_flat[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "IR (InputLayer)                 [(None, 20, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Discharge_time (InputLayer)     [(None, 20, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "QD (InputLayer)                 [(None, 20, 1)]      0                                            \n",
      "__________________________________________________________________________________________________\n",
      "all_concat (Concatenate)        (None, 20, 643)      0           dropout_cnn[0][0]                \n",
      "                                                                 IR[0][0]                         \n",
      "                                                                 Discharge_time[0][0]             \n",
      "                                                                 QD[0][0]                         \n",
      "__________________________________________________________________________________________________\n",
      "recurrent (LSTM)                (None, 128)          395264      all_concat[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_lstm (Dropout)          (None, 128)          0           recurrent[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "hidden (Dense)                  (None, 32)           4128        dropout_lstm[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "output (Dense)                  (None, 2)            66          hidden[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 492,418\n",
      "Trainable params: 492,418\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Epoch 1/70\n",
      "168/168 - 24s - loss: 0.0373 - mae_current_cycle: 362.1375 - mae_remaining_cycles: 212.1926 - val_loss: 0.0300 - val_mae_current_cycle: 260.4219 - val_mae_remaining_cycles: 175.1427\n",
      "Epoch 2/70\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp/ipykernel_41972/825261126.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     85\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     86\u001B[0m \u001B[1;31m# train model\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 87\u001B[1;33m history = model.fit(\n\u001B[0m\u001B[0;32m     88\u001B[0m     \u001B[0mdataset_train\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     89\u001B[0m     \u001B[0mepochs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m70\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001B[0m in \u001B[0;36mfit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1098\u001B[0m                 _r=1):\n\u001B[0;32m   1099\u001B[0m               \u001B[0mcallbacks\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mon_train_batch_begin\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mstep\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1100\u001B[1;33m               \u001B[0mtmp_logs\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtrain_function\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0miterator\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m   1101\u001B[0m               \u001B[1;32mif\u001B[0m \u001B[0mdata_handler\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mshould_sync\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m   1102\u001B[0m                 \u001B[0mcontext\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0masync_wait\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    826\u001B[0m     \u001B[0mtracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    827\u001B[0m     \u001B[1;32mwith\u001B[0m \u001B[0mtrace\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mTrace\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_name\u001B[0m\u001B[1;33m)\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0mtm\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 828\u001B[1;33m       \u001B[0mresult\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_call\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    829\u001B[0m       \u001B[0mcompiler\u001B[0m \u001B[1;33m=\u001B[0m \u001B[1;34m\"xla\"\u001B[0m \u001B[1;32mif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_experimental_compile\u001B[0m \u001B[1;32melse\u001B[0m \u001B[1;34m\"nonXla\"\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    830\u001B[0m       \u001B[0mnew_tracing_count\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mexperimental_get_tracing_count\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001B[0m in \u001B[0;36m_call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    853\u001B[0m       \u001B[1;31m# In this case we have created variables on the first call, so we run the\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    854\u001B[0m       \u001B[1;31m# defunned version which is guaranteed to never create variables.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 855\u001B[1;33m       \u001B[1;32mreturn\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateless_fn\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m*\u001B[0m\u001B[0margs\u001B[0m\u001B[1;33m,\u001B[0m \u001B[1;33m**\u001B[0m\u001B[0mkwds\u001B[0m\u001B[1;33m)\u001B[0m  \u001B[1;31m# pylint: disable=not-callable\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    856\u001B[0m     \u001B[1;32melif\u001B[0m \u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_stateful_fn\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mnot\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    857\u001B[0m       \u001B[1;31m# Release the lock early so that multiple threads can perform the call\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2940\u001B[0m       (graph_function,\n\u001B[0;32m   2941\u001B[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2942\u001B[1;33m     return graph_function._call_flat(\n\u001B[0m\u001B[0;32m   2943\u001B[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001B[0;32m   2944\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36m_call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1916\u001B[0m         and executing_eagerly):\n\u001B[0;32m   1917\u001B[0m       \u001B[1;31m# No tape is watching; skip to running the function.\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m-> 1918\u001B[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001B[0m\u001B[0;32m   1919\u001B[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001B[0;32m   1920\u001B[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001B[0m in \u001B[0;36mcall\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    553\u001B[0m       \u001B[1;32mwith\u001B[0m \u001B[0m_InterpolateFunctionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    554\u001B[0m         \u001B[1;32mif\u001B[0m \u001B[0mcancellation_manager\u001B[0m \u001B[1;32mis\u001B[0m \u001B[1;32mNone\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m--> 555\u001B[1;33m           outputs = execute.execute(\n\u001B[0m\u001B[0;32m    556\u001B[0m               \u001B[0mstr\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0msignature\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mname\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    557\u001B[0m               \u001B[0mnum_outputs\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mself\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_num_outputs\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;32mc:\\users\\pc-1\\documents\\github\\projectsprivate\\coin_cell_battery\\venv\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001B[0m in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m   \u001B[1;32mtry\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     58\u001B[0m     \u001B[0mctx\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mensure_initialized\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 59\u001B[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001B[0m\u001B[0;32m     60\u001B[0m                                         inputs, attrs, num_outputs)\n\u001B[0;32m     61\u001B[0m   \u001B[1;32mexcept\u001B[0m \u001B[0mcore\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0m_NotOkStatusException\u001B[0m \u001B[1;32mas\u001B[0m \u001B[0me\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# create model\n",
    "if args.model == 'split_model':\n",
    "    print(\"Using split model!\")\n",
    "    model = split_model.create_keras_model(window_size=ds_config[\"window_size\"],\n",
    "                                           loss=args.loss,\n",
    "                                           hparams_config=hparams)\n",
    "if args.model == 'full_cnn_model':\n",
    "    print(\"Using full cnn model!\")\n",
    "    model = full_cnn_model.create_keras_model(window_size=ds_config[\"window_size\"],\n",
    "                                              loss=args.loss,\n",
    "                                              hparams_config=hparams)\n",
    "\n",
    "# Calculate steps_per_epoch_train, steps_per_epoch_test\n",
    "# This is needed, since for counting repeat has to be false\n",
    "steps_per_epoch_train = calculate_steps_per_epoch(ds_train_path, ds_config)\n",
    "\n",
    "steps_per_epoch_validate = calculate_steps_per_epoch(ds_val_path, ds_config)\n",
    "\n",
    "# load datasets\n",
    "dataset_train = dp.create_dataset(data_dir=ds_train_path,\n",
    "                                  window_size=ds_config[\"window_size\"],\n",
    "                                  shift=ds_config[\"shift\"],\n",
    "                                  stride=ds_config[\"stride\"],\n",
    "                                  batch_size=ds_config[\"batch_size\"])\n",
    "\n",
    "dataset_validate = dp.create_dataset(data_dir=ds_val_path,\n",
    "                                     window_size=ds_config[\"window_size\"],\n",
    "                                     shift=ds_config[\"shift\"],\n",
    "                                     stride=ds_config[\"stride\"],\n",
    "                                     batch_size=ds_config[\"batch_size\"])\n",
    "\n",
    "# if hparams is passed, we're running a HPO-job\n",
    "if hparams:\n",
    "    checkpoint_callback = CustomCheckpoints(save_last_only=True,\n",
    "                                            log_dir=tboard,\n",
    "                                            dataset_path=ds_val_path,\n",
    "                                            dataset_config=ds_config,\n",
    "                                            save_eval_plot=False)\n",
    "else:\n",
    "    checkpoint_callback = CustomCheckpoints(save_best_only=True,\n",
    "                                            start_epoch=save_from,\n",
    "                                            log_dir=tboard,\n",
    "                                            dataset_path=ds_val_path,\n",
    "                                            dataset_config=ds_config,\n",
    "                                            save_eval_plot=False)\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.TensorBoard(log_dir=tboard,\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False,\n",
    "                                   ),\n",
    "    checkpoint_callback,\n",
    "]\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# train model\n",
    "history = model.fit(\n",
    "    dataset_train,\n",
    "    epochs=70,\n",
    "    steps_per_epoch=steps_per_epoch_train,\n",
    "    validation_data=dataset_validate,\n",
    "    validation_steps=steps_per_epoch_validate,\n",
    "    verbose=2,\n",
    "    callbacks=callbacks)\n",
    "\n",
    "mae_current = min(history.history[\"val_mae_current_cycle\"])\n",
    "mae_remaining = min(history.history[\"val_mae_remaining_cycles\"])\n",
    "\n",
    "#return mae_current, mae_remaining"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
